{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL-MovieReview.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOjKZTNx564dzl/QOceDVes",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lokeshkumarn/Notebooks/blob/master/DL_MovieReview.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2RPUuaO4wtQw"
      },
      "source": [
        "## Import Libraries/Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znWlj4p5ucwP"
      },
      "source": [
        "### Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-PDehKhrcQg"
      },
      "source": [
        "import time\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.client import device_lib\n",
        "from google.colab import drive\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random as rd\n",
        "\n",
        "from tensorflow import keras\n",
        "\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix,classification_report\n",
        "\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jepvGJP40Jsm"
      },
      "source": [
        "rd.seed(2020)         # Initialize the random number generator.\n",
        "np.random.seed(2020)      # With the seed reset, the same set of numbers will appear every time. \n",
        "tf.random.set_seed(2020)  # sets the graph-level random seed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxWChrxfumVf"
      },
      "source": [
        "### Import Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xs5teUjn2bmb"
      },
      "source": [
        "Load dataset from Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXDPNBPK2evf",
        "outputId": "286b3c2c-5d0d-4d1c-e4d0-381c44398e57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tps01oDj2ftY"
      },
      "source": [
        "df = pd.read_csv('/content/gdrive/My Drive/Colab Notebooks/Dataset/IMDB Dataset.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmtVHoKQ2ypl",
        "outputId": "49b857f4-b19b-4a31-8305-63f2272bf82d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        }
      },
      "source": [
        "df.head(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review sentiment\n",
              "0  One of the other reviewers has mentioned that ...  positive\n",
              "1  A wonderful little production. <br /><br />The...  positive"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8ibE97Q22V3",
        "outputId": "6dfa96fb-34da-4162-d0ea-77f7eca96cfc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKDM0pgWvG1Y"
      },
      "source": [
        "### Check GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ow9Gj9dXtvBA",
        "outputId": "06736ac4-ab79-4e64-e2e4-0834f6349dd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "def get_available_gpus():\n",
        "    local_device_protos = device_lib.list_local_devices()\n",
        "    return [x.name for x in local_device_protos if x.device_type == 'GPU' ]\n",
        "\n",
        "gpu_lst = get_available_gpus()\n",
        "\n",
        "if(len(gpu_lst) > 0):\n",
        "  print(\"GPU Enabled\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU Enabled\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qtu-rmbw1Mz"
      },
      "source": [
        "## Data Visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNT-w_9ANnwj"
      },
      "source": [
        "### Print Reviews"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "467gA9LXJU4W"
      },
      "source": [
        "Print at least two movie reviews from each class of the dataset, for a sanity check that labels match the text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnQ_okd44HrF",
        "outputId": "569b7c8f-3ece-475a-f612-4e61e399ca33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        }
      },
      "source": [
        "print(\"Positive Reviews\")\n",
        "print(\"*\"*30)\n",
        "for i,r in df[df['sentiment'] =='positive'].reset_index()[:3].iterrows():\n",
        "  print(i + 1,\")\",r['review'])\n",
        "  print(\"\\n\")\n",
        "\n",
        "print(\"Negative Reviews\")\n",
        "print(\"*\"*30)\n",
        "for i,r in df[df['sentiment'] =='negative'].reset_index()[:3].iterrows():\n",
        "  print(i + 1,\")\",r['review'])\n",
        "  print(\"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Positive Reviews\n",
            "******************************\n",
            "1 ) One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.<br /><br />The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.<br /><br />It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.<br /><br />I would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. Forget pretty pictures painted for mainstream audiences, forget charm, forget romance...OZ doesn't mess around. The first episode I ever saw struck me as so nasty it was surreal, I couldn't say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence. Not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) Watching Oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.\n",
            "\n",
            "\n",
            "2 ) A wonderful little production. <br /><br />The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece. <br /><br />The actors are extremely well chosen- Michael Sheen not only \"has got all the polari\" but he has all the voices down pat too! You can truly see the seamless editing guided by the references to Williams' diary entries, not only is it well worth the watching but it is a terrificly written and performed piece. A masterful production about one of the great master's of comedy and his life. <br /><br />The realism really comes home with the little things: the fantasy of the guard which, rather than use the traditional 'dream' techniques remains solid then disappears. It plays on our knowledge and our senses, particularly with the scenes concerning Orton and Halliwell and the sets (particularly of their flat with Halliwell's murals decorating every surface) are terribly well done.\n",
            "\n",
            "\n",
            "3 ) I thought this was a wonderful way to spend time on a too hot summer weekend, sitting in the air conditioned theater and watching a light-hearted comedy. The plot is simplistic, but the dialogue is witty and the characters are likable (even the well bread suspected serial killer). While some may be disappointed when they realize this is not Match Point 2: Risk Addiction, I thought it was proof that Woody Allen is still fully in control of the style many of us have grown to love.<br /><br />This was the most I'd laughed at one of Woody's comedies in years (dare I say a decade?). While I've never been impressed with Scarlet Johanson, in this she managed to tone down her \"sexy\" image and jumped right into a average, but spirited young woman.<br /><br />This may not be the crown jewel of his career, but it was wittier than \"Devil Wears Prada\" and more interesting than \"Superman\" a great comedy to go see with friends.\n",
            "\n",
            "\n",
            "Negative Reviews\n",
            "******************************\n",
            "1 ) Basically there's a family where a little boy (Jake) thinks there's a zombie in his closet & his parents are fighting all the time.<br /><br />This movie is slower than a soap opera... and suddenly, Jake decides to become Rambo and kill the zombie.<br /><br />OK, first of all when you're going to make a film you must Decide if its a thriller or a drama! As a drama the movie is watchable. Parents are divorcing & arguing like in real life. And then we have Jake with his closet which totally ruins all the film! I expected to see a BOOGEYMAN similar movie, and instead i watched a drama with some meaningless thriller spots.<br /><br />3 out of 10 just for the well playing parents & descent dialogs. As for the shots with Jake: just ignore them.\n",
            "\n",
            "\n",
            "2 ) This show was an amazing, fresh & innovative idea in the 70's when it first aired. The first 7 or 8 years were brilliant, but things dropped off after that. By 1990, the show was not really funny anymore, and it's continued its decline further to the complete waste of time it is today.<br /><br />It's truly disgraceful how far this show has fallen. The writing is painfully bad, the performances are almost as bad - if not for the mildly entertaining respite of the guest-hosts, this show probably wouldn't still be on the air. I find it so hard to believe that the same creator that hand-selected the original cast also chose the band of hacks that followed. How can one recognize such brilliance and then see fit to replace it with such mediocrity? I felt I must give 2 stars out of respect for the original cast that made this show such a huge success. As it is now, the show is just awful. I can't believe it's still on the air.\n",
            "\n",
            "\n",
            "3 ) Encouraged by the positive comments about this film on here I was looking forward to watching this film. Bad mistake. I've seen 950+ films and this is truly one of the worst of them - it's awful in almost every way: editing, pacing, storyline, 'acting,' soundtrack (the film's only song - a lame country tune - is played no less than four times). The film looks cheap and nasty and is boring in the extreme. Rarely have I been so happy to see the end credits of a film. <br /><br />The only thing that prevents me giving this a 1-score is Harvey Keitel - while this is far from his best performance he at least seems to be making a bit of an effort. One for Keitel obsessives only.\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zs_9PIlHNtp6"
      },
      "source": [
        "### Plot Class Distribution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYYLAI_-L-Ld"
      },
      "source": [
        "Plot a bar graph of class distribution in dataset. Each bar depicts the number of tweets belonging to a particular sentiment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nr7boPTB5jDL",
        "outputId": "2d46db0b-be3e-4a52-dcc0-bc3c86c90c89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        }
      },
      "source": [
        "ax = plt.subplot()\n",
        "df['sentiment'].value_counts().plot(kind='barh',ax=ax)\n",
        "ax.set_title(\"Distribution of the Sentiment in IMDB reviews\")\n",
        "ax.set_xlabel(\"Count\")\n",
        "ax.set_ylabel(\"Sentiment\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Sentiment')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iowvMxjbhn9w"
      },
      "source": [
        "### Print the shapes of train and test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4SHG8fY7ccL"
      },
      "source": [
        "df['class'] = df['sentiment'].apply(lambda x:  1 if x=='positive' else 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFVa_UoF8zQi",
        "outputId": "6d12a0b8-714d-4d99-86fc-6d432153b014",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "X = df['review'].values\n",
        "y = df['class'].values\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000,)\n",
            "(50000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PwW1kHCK7HA9"
      },
      "source": [
        "X_train,X_test,y_train,y_test = train_test_split(X,y,\n",
        "                                                 test_size=0.3,\n",
        "                                                 shuffle=True,\n",
        "                                                 stratify=y,\n",
        "                                                 random_state=2020)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pgw1cqFxnYM",
        "outputId": "19865b54-c27f-4c6d-8734-e14a37847090",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "print('Train Features shape:',X_train.shape)\n",
        "print('Test Features shape:',X_test.shape)\n",
        "print('Train label shape:',y_train.shape)\n",
        "print('Test label shape:',y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Features shape: (35000,)\n",
            "Test Features shape: (15000,)\n",
            "Train label shape: (35000,)\n",
            "Test label shape: (15000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xoNC64FA-Fux",
        "outputId": "7a023101-81e4-485e-a93e-e7a81de23005",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        }
      },
      "source": [
        "#Verify whether stratification worked\n",
        "fig,ax = plt.subplots(1,2,figsize=(15,5))\n",
        "pd.Series(y_train).value_counts().plot(kind='barh',ax=ax[0])\n",
        "pd.Series(y_test).value_counts().plot(kind='barh',ax=ax[1])\n",
        "ax[0].set_title(\"Distribution of the Sentiment in Train\")\n",
        "ax[0].set_xlabel(\"Count\")\n",
        "ax[0].set_ylabel(\"Sentiment\")\n",
        "ax[1].set_title(\"Distribution of the Sentiment in Test\")\n",
        "ax[1].set_xlabel(\"Count\")\n",
        "ax[1].set_ylabel(\"Sentiment\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Sentiment')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tsa0onWR9Zz0"
      },
      "source": [
        "## Data Pre-processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RIXUGbLQC_sK"
      },
      "source": [
        "Need for this Step - Since the models we use cannot accept string inputs or cannot be of the string format. We have to come up with a way of handling this step."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCy1RDPaDH6-"
      },
      "source": [
        "Using the Pretrained embedding layer to convert the sentence to vector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JN7TYKh6E6Vh"
      },
      "source": [
        "hub_layer = hub.KerasLayer(\"https://tfhub.dev/google/nnlm-en-dim128/1\",output_shape=128,\n",
        "                           input_shape=[], dtype=tf.string)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJZcForeH69P"
      },
      "source": [
        "## Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6IGxAutlE7SI"
      },
      "source": [
        "### Model Building"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EjTVigauHWfh"
      },
      "source": [
        "Sequential Model layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ck9MYQsrHOOU"
      },
      "source": [
        "model = keras.Sequential()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_2YQZ8aHZL4"
      },
      "source": [
        "1.   Add L2 regularization to all the layers.\n",
        "2.   Add one layer of dropout at the appropriate position and give reasons.\n",
        "3.   Choose the appropriate activation function for all the layers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9CFFVJLCNfI"
      },
      "source": [
        "**Hidden Unit selection** are hyperparameters <br/>\n",
        "For each parameter, decide a range and steps into that range, like 8 to 64 neurons, in powers of two (8, 16, 32, 64), and try each combination of the parameters. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ou0v2LPYDROO"
      },
      "source": [
        "So I decided to reduce the number of parameters to learn as layers proceed, gave 64 and then **50% dropout** to further reduce the parameter to learn and also avoid overfitting, later 16 units to futher reduce the complexity of learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JD290TmlHMAC"
      },
      "source": [
        "hub_layer = hub.KerasLayer(\"https://tfhub.dev/google/nnlm-en-dim128/1\",output_shape=128,\n",
        "                           input_shape=[], dtype=tf.string)\n",
        "\n",
        "model = keras.Sequential()\n",
        "\n",
        "model.add(hub_layer)\n",
        "\n",
        "model.add(keras.layers.Dense(64, activation='relu',kernel_regularizer=keras.regularizers.l2(0.01),\n",
        "                activity_regularizer=keras.regularizers.l2(0.01)) )\n",
        "\n",
        "model.add(keras.layers.Dense(64, activation='relu',kernel_regularizer=keras.regularizers.l2(0.01),\n",
        "                activity_regularizer=keras.regularizers.l2(0.01)))\n",
        "\n",
        "model.add(keras.layers.Dropout(0.5))\n",
        "\n",
        "model.add(keras.layers.Dense(16, activation='relu',kernel_regularizer=keras.regularizers.l2(0.01),\n",
        "                activity_regularizer=keras.regularizers.l2(0.01)))\n",
        "\n",
        "model.add(keras.layers.Dense(1, activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLnT3omTHRQz"
      },
      "source": [
        "Print the model summary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RpDg4HzGBLbG",
        "outputId": "5a4b6753-0183-44c9-a45b-b0e35fe4c595",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "keras_layer_6 (KerasLayer)   (None, 128)               249285376 \n",
            "_________________________________________________________________\n",
            "dense_24 (Dense)             (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_25 (Dense)             (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_26 (Dense)             (None, 16)                1040      \n",
            "_________________________________________________________________\n",
            "dense_27 (Dense)             (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 249,298,849\n",
            "Trainable params: 13,473\n",
            "Non-trainable params: 249,285,376\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYrP0fSCHuVC"
      },
      "source": [
        "### Model Compilation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36kwbeBcEPdV"
      },
      "source": [
        "**Loss** : Binary Cross Entropy (because it's a binary classification problem <br/>\n",
        "**Optimizer**: Adam  is an extension of the stochastic gradient descent and seen extensivelty used in Natural language processing. it has adaptive learning rate.\n",
        "***Didn't choose a higher learning rate because wanted the network learn appropriately based on the distribution change in data***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6SQsMfMBO3l"
      },
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01,name='Adam'),#Use an appropriate optimizer\n",
        "              loss='binary_crossentropy',#appropriate loss function\n",
        "              metrics=['accuracy'])#Use accuracy as metric"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ku_o9m2AIDYm"
      },
      "source": [
        "### Model Training "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kvAGUr2vINU_"
      },
      "source": [
        "Train the model for an appropriate number of epochs (print the train and validation accuracy/loss for each epoch). Use the appropriate batch size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdJtX3PKBfgK",
        "outputId": "a0124a55-2420-4c01-d8ed-86a67bd873df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "start_train = time.time()\n",
        "history = model.fit(X_train,\n",
        "                    y_train,\n",
        "                    epochs=50,\n",
        "                    batch_size=1000,\n",
        "                    validation_split=0.2,\n",
        "                    verbose=1)\n",
        "end_train = time.time()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "28/28 [==============================] - 2s 58ms/step - loss: 1.0547 - accuracy: 0.6760 - val_loss: 0.6417 - val_accuracy: 0.7554\n",
            "Epoch 2/50\n",
            "28/28 [==============================] - 1s 52ms/step - loss: 0.5961 - accuracy: 0.7719 - val_loss: 0.5533 - val_accuracy: 0.7853\n",
            "Epoch 3/50\n",
            "28/28 [==============================] - 1s 53ms/step - loss: 0.5561 - accuracy: 0.7805 - val_loss: 0.5438 - val_accuracy: 0.7789\n",
            "Epoch 4/50\n",
            "28/28 [==============================] - 1s 52ms/step - loss: 0.5451 - accuracy: 0.7801 - val_loss: 0.5351 - val_accuracy: 0.7873\n",
            "Epoch 5/50\n",
            "28/28 [==============================] - 2s 54ms/step - loss: 0.5413 - accuracy: 0.7816 - val_loss: 0.5327 - val_accuracy: 0.7789\n",
            "Epoch 6/50\n",
            "28/28 [==============================] - 1s 53ms/step - loss: 0.5355 - accuracy: 0.7819 - val_loss: 0.5305 - val_accuracy: 0.7777\n",
            "Epoch 7/50\n",
            "28/28 [==============================] - 1s 52ms/step - loss: 0.5470 - accuracy: 0.7730 - val_loss: 0.5277 - val_accuracy: 0.7850\n",
            "Epoch 8/50\n",
            "28/28 [==============================] - 1s 52ms/step - loss: 0.5343 - accuracy: 0.7797 - val_loss: 0.5118 - val_accuracy: 0.7903\n",
            "Epoch 9/50\n",
            "28/28 [==============================] - 1s 53ms/step - loss: 0.5257 - accuracy: 0.7861 - val_loss: 0.5136 - val_accuracy: 0.7880\n",
            "Epoch 10/50\n",
            "28/28 [==============================] - 1s 53ms/step - loss: 0.5305 - accuracy: 0.7826 - val_loss: 0.5232 - val_accuracy: 0.7811\n",
            "Epoch 11/50\n",
            "28/28 [==============================] - 1s 53ms/step - loss: 0.5277 - accuracy: 0.7815 - val_loss: 0.5105 - val_accuracy: 0.7887\n",
            "Epoch 12/50\n",
            "28/28 [==============================] - 1s 53ms/step - loss: 0.5225 - accuracy: 0.7849 - val_loss: 0.5102 - val_accuracy: 0.7859\n",
            "Epoch 13/50\n",
            "28/28 [==============================] - 1s 53ms/step - loss: 0.5193 - accuracy: 0.7871 - val_loss: 0.5121 - val_accuracy: 0.7791\n",
            "Epoch 14/50\n",
            "28/28 [==============================] - 1s 52ms/step - loss: 0.5214 - accuracy: 0.7832 - val_loss: 0.5049 - val_accuracy: 0.7871\n",
            "Epoch 15/50\n",
            "28/28 [==============================] - 2s 54ms/step - loss: 0.5179 - accuracy: 0.7855 - val_loss: 0.5177 - val_accuracy: 0.7799\n",
            "Epoch 16/50\n",
            "28/28 [==============================] - 1s 52ms/step - loss: 0.5220 - accuracy: 0.7830 - val_loss: 0.5033 - val_accuracy: 0.7870\n",
            "Epoch 17/50\n",
            "28/28 [==============================] - 1s 53ms/step - loss: 0.5155 - accuracy: 0.7865 - val_loss: 0.5032 - val_accuracy: 0.7881\n",
            "Epoch 18/50\n",
            "28/28 [==============================] - 1s 53ms/step - loss: 0.5136 - accuracy: 0.7866 - val_loss: 0.5062 - val_accuracy: 0.7851\n",
            "Epoch 19/50\n",
            "28/28 [==============================] - 1s 53ms/step - loss: 0.5183 - accuracy: 0.7847 - val_loss: 0.5039 - val_accuracy: 0.7897\n",
            "Epoch 20/50\n",
            "28/28 [==============================] - 1s 53ms/step - loss: 0.5138 - accuracy: 0.7870 - val_loss: 0.4964 - val_accuracy: 0.7929\n",
            "Epoch 21/50\n",
            "28/28 [==============================] - 1s 52ms/step - loss: 0.5149 - accuracy: 0.7873 - val_loss: 0.5023 - val_accuracy: 0.7879\n",
            "Epoch 22/50\n",
            "28/28 [==============================] - 1s 53ms/step - loss: 0.5165 - accuracy: 0.7831 - val_loss: 0.5025 - val_accuracy: 0.7884\n",
            "Epoch 23/50\n",
            "28/28 [==============================] - 1s 53ms/step - loss: 0.5199 - accuracy: 0.7814 - val_loss: 0.5145 - val_accuracy: 0.7799\n",
            "Epoch 24/50\n",
            "28/28 [==============================] - 2s 54ms/step - loss: 0.5157 - accuracy: 0.7872 - val_loss: 0.4967 - val_accuracy: 0.7909\n",
            "Epoch 25/50\n",
            "28/28 [==============================] - 1s 53ms/step - loss: 0.5171 - accuracy: 0.7834 - val_loss: 0.4992 - val_accuracy: 0.7873\n",
            "Epoch 26/50\n",
            "28/28 [==============================] - 1s 52ms/step - loss: 0.5078 - accuracy: 0.7896 - val_loss: 0.5118 - val_accuracy: 0.7826\n",
            "Epoch 27/50\n",
            "28/28 [==============================] - 1s 53ms/step - loss: 0.5181 - accuracy: 0.7823 - val_loss: 0.4953 - val_accuracy: 0.7916\n",
            "Epoch 28/50\n",
            "28/28 [==============================] - 1s 52ms/step - loss: 0.5117 - accuracy: 0.7843 - val_loss: 0.4967 - val_accuracy: 0.7941\n",
            "Epoch 29/50\n",
            "28/28 [==============================] - 1s 52ms/step - loss: 0.5064 - accuracy: 0.7886 - val_loss: 0.4944 - val_accuracy: 0.7904\n",
            "Epoch 30/50\n",
            "28/28 [==============================] - 1s 53ms/step - loss: 0.5068 - accuracy: 0.7893 - val_loss: 0.4954 - val_accuracy: 0.7900\n",
            "Epoch 31/50\n",
            "28/28 [==============================] - 1s 52ms/step - loss: 0.5089 - accuracy: 0.7865 - val_loss: 0.4948 - val_accuracy: 0.7887\n",
            "Epoch 32/50\n",
            "28/28 [==============================] - 1s 53ms/step - loss: 0.5032 - accuracy: 0.7891 - val_loss: 0.4926 - val_accuracy: 0.7901\n",
            "Epoch 33/50\n",
            "28/28 [==============================] - 1s 53ms/step - loss: 0.5121 - accuracy: 0.7809 - val_loss: 0.5019 - val_accuracy: 0.7820\n",
            "Epoch 34/50\n",
            "28/28 [==============================] - 1s 53ms/step - loss: 0.5061 - accuracy: 0.7877 - val_loss: 0.4920 - val_accuracy: 0.7929\n",
            "Epoch 35/50\n",
            "28/28 [==============================] - 1s 53ms/step - loss: 0.5013 - accuracy: 0.7874 - val_loss: 0.4942 - val_accuracy: 0.7874\n",
            "Epoch 36/50\n",
            "28/28 [==============================] - 1s 53ms/step - loss: 0.5012 - accuracy: 0.7912 - val_loss: 0.4938 - val_accuracy: 0.7900\n",
            "Epoch 37/50\n",
            "28/28 [==============================] - 1s 53ms/step - loss: 0.5054 - accuracy: 0.7880 - val_loss: 0.4921 - val_accuracy: 0.7911\n",
            "Epoch 38/50\n",
            "28/28 [==============================] - 1s 53ms/step - loss: 0.5261 - accuracy: 0.7775 - val_loss: 0.5265 - val_accuracy: 0.7690\n",
            "Epoch 39/50\n",
            "28/28 [==============================] - 1s 53ms/step - loss: 0.5137 - accuracy: 0.7843 - val_loss: 0.5210 - val_accuracy: 0.7767\n",
            "Epoch 40/50\n",
            "28/28 [==============================] - 1s 53ms/step - loss: 0.5036 - accuracy: 0.7887 - val_loss: 0.4904 - val_accuracy: 0.7894\n",
            "Epoch 41/50\n",
            "28/28 [==============================] - 1s 53ms/step - loss: 0.5013 - accuracy: 0.7912 - val_loss: 0.5119 - val_accuracy: 0.7830\n",
            "Epoch 42/50\n",
            "28/28 [==============================] - 1s 52ms/step - loss: 0.5088 - accuracy: 0.7879 - val_loss: 0.4909 - val_accuracy: 0.7927\n",
            "Epoch 43/50\n",
            "28/28 [==============================] - 1s 53ms/step - loss: 0.5045 - accuracy: 0.7878 - val_loss: 0.4917 - val_accuracy: 0.7916\n",
            "Epoch 44/50\n",
            "28/28 [==============================] - 1s 53ms/step - loss: 0.5022 - accuracy: 0.7854 - val_loss: 0.5149 - val_accuracy: 0.7761\n",
            "Epoch 45/50\n",
            "28/28 [==============================] - 2s 54ms/step - loss: 0.5073 - accuracy: 0.7880 - val_loss: 0.4875 - val_accuracy: 0.7927\n",
            "Epoch 46/50\n",
            "28/28 [==============================] - 2s 54ms/step - loss: 0.5002 - accuracy: 0.7906 - val_loss: 0.4941 - val_accuracy: 0.7870\n",
            "Epoch 47/50\n",
            "28/28 [==============================] - 1s 54ms/step - loss: 0.4970 - accuracy: 0.7918 - val_loss: 0.4917 - val_accuracy: 0.7914\n",
            "Epoch 48/50\n",
            "28/28 [==============================] - 1s 53ms/step - loss: 0.5075 - accuracy: 0.7848 - val_loss: 0.4979 - val_accuracy: 0.7876\n",
            "Epoch 49/50\n",
            "28/28 [==============================] - 2s 54ms/step - loss: 0.4994 - accuracy: 0.7903 - val_loss: 0.4909 - val_accuracy: 0.7899\n",
            "Epoch 50/50\n",
            "28/28 [==============================] - 2s 55ms/step - loss: 0.4986 - accuracy: 0.7886 - val_loss: 0.4955 - val_accuracy: 0.7863\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8Vx-IVoISSh"
      },
      "source": [
        "Plot the loss and accuracy history graphs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKj_nkxKBjPd",
        "outputId": "8ccc5a5c-83d7-4f3d-9af0-fac64aa95ddd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "history_dict = history.history\n",
        "print(history_dict.keys())\n",
        "\n",
        "acc = history_dict['accuracy']\n",
        "val_acc = history_dict['val_accuracy']\n",
        "loss = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "fix,ax = plt.subplots(1,2, figsize=(15,5))\n",
        "ax1 = ax[0] # to plot Training Loss\n",
        "ax2 = ax[1] # to plot Training Accuracy\n",
        "\n",
        "ax1.plot(epochs, loss, 'b', label='Training loss')# \"bo\" is for \"blue dot\"\n",
        "ax1.plot(epochs, val_loss, 'r', label='Validation loss')# b is for \"solid blue line\"\n",
        "ax1.set_title('Training and validation loss')\n",
        "ax1.set_xlabel('Epochs')\n",
        "ax1.set_ylabel('Loss')\n",
        "ax1.legend()\n",
        "\n",
        "ax2.plot(epochs, acc, 'b', label='Training acc')\n",
        "ax2.plot(epochs, val_acc, 'r', label='Validation acc')\n",
        "ax2.set_title('Training and validation accuracy')\n",
        "ax2.set_xlabel('Epochs')\n",
        "ax2.set_ylabel('Accuracy')\n",
        "ax2.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gBvMgheHT4l",
        "outputId": "554456cc-5682-49b1-ff2d-7703f251dfad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#Time taken to train\n",
        "print(\"Time taken to train the NN:\",end_train - start_train,\" seconds\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time taken to train the NN: 77.25413489341736  seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3aSraejcjKc"
      },
      "source": [
        "### Model Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HYmr-whel7t"
      },
      "source": [
        "Print the final test/validation loss and accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ij8-utLRcm4l",
        "outputId": "c38b7a3e-29f5-4c7e-b24d-4464b9289945",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "results = model.evaluate(X_test, y_test)\n",
        "\n",
        "print(\"Test Loss:\",results[0])\n",
        "print(\"Test Accuracy:\",results[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "469/469 [==============================] - 2s 5ms/step - loss: 0.4921 - accuracy: 0.7919\n",
            "Test Loss: 0.49208223819732666\n",
            "Test Accuracy: 0.791866660118103\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWHlK7ZXdOm7"
      },
      "source": [
        "#Predictions\n",
        "y_pred = model.predict_classes(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2BlOz_seRb6"
      },
      "source": [
        "Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLGiz00ydSCx",
        "outputId": "f039d961-16be-42ff-ccf1-97cd0825b0c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "print(\"Confustion Matrix\")\n",
        "print(confusion_matrix(y_test,y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confustion Matrix\n",
            "[[6451 1049]\n",
            " [2073 5427]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-QbNW7WOtgS"
      },
      "source": [
        "y_pred = [v[0] for v in y_pred]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMYJFs5COMco",
        "outputId": "3cab6a71-a098-4d3b-c22f-7668b5da6184",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "df = pd.DataFrame({'y_test':y_test,'y_pred':y_pred})\n",
        "df.head()\n",
        "confusion_matrix = pd.crosstab(df['y_test'], df['y_pred'], rownames=['Actual'], colnames=['Predicted'])\n",
        "print (confusion_matrix)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted     0     1\n",
            "Actual               \n",
            "0          6451  1049\n",
            "1          2073  5427\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVfGEO-veXjl"
      },
      "source": [
        "Classification Report"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uD9BUP1jdmHw",
        "outputId": "083d7b5b-6f92-4ad1-f780-f48a5bba8df0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        }
      },
      "source": [
        "print(classification_report(y_test,y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.82      0.80      7500\n",
            "           1       0.81      0.77      0.79      7500\n",
            "\n",
            "    accuracy                           0.80     15000\n",
            "   macro avg       0.80      0.80      0.80     15000\n",
            "weighted avg       0.80      0.80      0.80     15000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blafKSc3exSx"
      },
      "source": [
        "**Write a summary for the best and worst performing class and the overall trend??**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLwP--FUPHEl"
      },
      "source": [
        "Worst performing class is postive class because compared to the negative sentiment most of the positive sentiment is predicted incorrectly by the model. <br/>\n",
        "In the first 10 epochs itself model was able to acheive the accuracy of 77+, however still continue to train for 50 epochs ,we haven't introduced the callbacks like early stopping to stop the train if score doesn't improve much.\n",
        "\n",
        "We will try to move the Drop out to different position and will reduce or increase the batch size in the subsequent trainings"
      ]
    }
  ]
}